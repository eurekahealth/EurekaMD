import argparse
import os
import time
from tqdm import tqdm

import pandas as pd
from notdiamond import NotDiamond

from prompts import create_examples, get_prompt_for_not_diamond

if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument("--preference-id", type=str, required=True, help="The preference id of the trained router model.")
    parser.add_argument("--output-file-location", type=str, default='data/generated/router_preferences.csv', help="The location to output the router preferences.")
    parser.add_argument("--train-data-file-location", type=str, default="data/questions/medqa_4_options_train.jsonl", help="The location of the train data file.")
    parser.add_argument("--test-data-file-location", type=str, default="data/questions/medqa_4_options_test.jsonl", help="The location of the test data file.")
    parser.add_argument("--similar-questions-file-location", type=str, default="data/generated/similar_training_questions_to_test.csv", help="The location of the file mapping training questions to similar test questions.")
    parser.add_argument("--gpt-cot-file-location", type=str, default="data/generated/gpt-4o_training_cots.csv", help="The location of the training chain of thoughts generated by gpt.")
    parser.add_argument("--llama-cot-file-location", type=str, default="data/generated/llama_training_cots.csv", help="The location of the training chain of thoughts generated by llama.")
    parser.add_argument("--num-examples", type=int, default=5, help="The number of examples to inject for in-context learning.")
    args, _ = parser.parse_known_args()

    client = NotDiamond()
    model_list = ['openai/gpt-4o', 'openai/gpt-4o-no-cot', 'fireworks/accounts/fireworks/models/llama-v3p1-405b-instruct' 'fireworks/accounts/fireworks/models/llama-v3p1-405b-instruct-no-cot']

    train_df = pd.read_json(args.train_data_file_location, lines=True)
    test_df = pd.read_json(args.test_data_file_location, lines=True)
    similar_training_questions = pd.read_csv(args.similar_questions_file_location)
    gpt_cot_df = pd.read_csv(args.gpt_cot_file_location)
    llama_cot_df = pd.read_csv(args.llama_cot_file_location)

    results = list()
    for test_idx, row in tqdm(test_df.iterrows(), total=len(test_df)):
        similar_train_rows = similar_training_questions[similar_training_questions['test_idx'] == test_idx]
        similar_train_rows = similar_train_rows['train_idx'].tolist()

        examples = create_examples(similar_train_rows, train_df, gpt_cot_df, llama_cot_df, max_examples=args.num_examples)
        prompt = get_prompt_for_not_diamond(row['question'], row['options'], examples)

        session_id, provider = client.chat.completions.model_select(
            messages=[
                {"role": "user", "content": prompt},
            ],
            model=model_list,
            preference_id=args.preference_id,
        )
        results.append(provider)
        print(provider)
        time.sleep(0.5)

    model_ids = list()
    use_cots = list()
    for result in results:
        model_ids.append(result.model.replace('-no-cot', ''))

        if "no-cot" in result.model:
            use_cots.append(False)
        else:
            use_cots.append(True)

    preference_df = pd.DataFrame({
        'test_idx': test_df.index.tolist(),
        'model': model_ids,
        'use_cot': use_cots
    })
    preference_df.to_csv(args.output_file_location, index=False)
